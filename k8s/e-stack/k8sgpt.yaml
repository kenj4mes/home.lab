# ==============================================================================
# ðŸ¤– K8sGPT - AI-Powered Kubernetes SRE
# ==============================================================================
# Scans cluster for issues and uses LLM to explain fixes
# Uses local Ollama for 100% private analysis
# ==============================================================================

apiVersion: v1
kind: Namespace
metadata:
  name: k8sgpt
  labels:
    app.kubernetes.io/name: k8sgpt
    app.kubernetes.io/part-of: ai-ops

---
# ==============================================================================
# K8sGPT Custom Resource (for Operator mode)
# ==============================================================================
apiVersion: core.k8sgpt.ai/v1alpha1
kind: K8sGPT
metadata:
  name: k8sgpt-local
  namespace: k8sgpt
spec:
  ai:
    enabled: true
    # Use 'localai' backend for Ollama compatibility
    backend: localai
    model: llama3.1:8b
    # Internal cluster DNS to Ollama service
    # IMPORTANT: Must end in /v1 for OpenAI API compatibility
    baseUrl: http://ollama.ollama.svc.cluster.local:11434/v1
    # Enable caching to reduce LLM calls
    noCache: false
  
  # Kubernetes analyzers to enable
  filters:
    - Pod
    - Deployment
    - Service
    - Ingress
    - StatefulSet
    - ReplicaSet
    - PersistentVolumeClaim
    - Node
    - NetworkPolicy
    - HorizontalPodAutoscaler
    - CronJob
    - Job
  
  # Sink for results (optional)
  # sink:
  #   type: slack
  #   webhook: "https://hooks.slack.com/..."
  
  # Analysis interval
  repository: {}
  noCache: false
  version: v0.3.29

---
# ==============================================================================
# K8sGPT Operator CRDs (install via Helm, these are for reference)
# ==============================================================================
# The operator watches for K8sGPT resources and runs analysis

---
# ==============================================================================
# K8sGPT CLI Deployment (Alternative to Operator)
# ==============================================================================
apiVersion: apps/v1
kind: Deployment
metadata:
  name: k8sgpt-cli
  namespace: k8sgpt
  labels:
    app: k8sgpt-cli
spec:
  replicas: 1
  selector:
    matchLabels:
      app: k8sgpt-cli
  template:
    metadata:
      labels:
        app: k8sgpt-cli
    spec:
      serviceAccountName: k8sgpt
      containers:
        - name: k8sgpt
          image: ghcr.io/k8sgpt-ai/k8sgpt:v0.3.29
          command:
            - "/bin/sh"
            - "-c"
            - |
              # Configure backend to use local Ollama
              k8sgpt auth add --backend localai --model llama3.1:8b --baseurl http://ollama.ollama.svc.cluster.local:11434/v1
              k8sgpt auth default --provider localai
              
              # Run continuous analysis every 5 minutes
              while true; do
                echo "=== K8sGPT Analysis $(date) ==="
                k8sgpt analyze --explain --with-doc
                sleep 300
              done
          
          env:
            - name: K8SGPT_BACKEND
              value: "localai"
            - name: K8SGPT_MODEL
              value: "llama3.1:8b"
            - name: K8SGPT_BASEURL
              value: "http://ollama.ollama.svc.cluster.local:11434/v1"
          
          resources:
            requests:
              memory: "128Mi"
              cpu: "50m"
            limits:
              memory: "512Mi"
              cpu: "500m"

---
# ==============================================================================
# Service Account with cluster-wide read access
# ==============================================================================
apiVersion: v1
kind: ServiceAccount
metadata:
  name: k8sgpt
  namespace: k8sgpt

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8sgpt-reader
rules:
  - apiGroups: [""]
    resources: ["*"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["apps"]
    resources: ["*"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["batch"]
    resources: ["*"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["networking.k8s.io"]
    resources: ["*"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["autoscaling"]
    resources: ["*"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["policy"]
    resources: ["*"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["storage.k8s.io"]
    resources: ["*"]
    verbs: ["get", "list", "watch"]

---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8sgpt-reader
subjects:
  - kind: ServiceAccount
    name: k8sgpt
    namespace: k8sgpt
roleRef:
  kind: ClusterRole
  name: k8sgpt-reader
  apiGroup: rbac.authorization.k8s.io

---
# ==============================================================================
# CronJob for Scheduled Analysis
# ==============================================================================
apiVersion: batch/v1
kind: CronJob
metadata:
  name: k8sgpt-analysis
  namespace: k8sgpt
spec:
  schedule: "0 */6 * * *"  # Every 6 hours
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: k8sgpt
          restartPolicy: OnFailure
          containers:
            - name: k8sgpt
              image: ghcr.io/k8sgpt-ai/k8sgpt:v0.3.29
              command:
                - "/bin/sh"
                - "-c"
                - |
                  k8sgpt auth add --backend localai --model llama3.1:8b --baseurl http://ollama.ollama.svc.cluster.local:11434/v1
                  k8sgpt auth default --provider localai
                  k8sgpt analyze --explain --with-doc --output json > /tmp/analysis.json
                  cat /tmp/analysis.json
              resources:
                requests:
                  memory: "128Mi"
                  cpu: "100m"
                limits:
                  memory: "512Mi"
                  cpu: "500m"
